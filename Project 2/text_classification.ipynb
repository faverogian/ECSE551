{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Suppress output of following line and do not output True or False\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the training data from the given .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset and remove non-utf-8 characters\n",
    "df = pd.read_csv('train.csv', encoding='cp1252')\n",
    "df.columns = ['body', 'subreddit']\n",
    "\n",
    "# Convert all characters to lowercase\n",
    "df['body'] = df['body'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before pre-processing the data, it can be helpful to identify the characters we are dealing with in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>59253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>34050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>24093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>21378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o</td>\n",
       "      <td>20234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i</td>\n",
       "      <td>19135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n</td>\n",
       "      <td>19085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s</td>\n",
       "      <td>18262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>r</td>\n",
       "      <td>16288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l</td>\n",
       "      <td>12045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character  frequency\n",
       "0                59253\n",
       "1         e      34050\n",
       "2         t      24093\n",
       "3         a      21378\n",
       "4         o      20234\n",
       "5         i      19135\n",
       "6         n      19085\n",
       "7         s      18262\n",
       "8         r      16288\n",
       "9         l      12045"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the frequency of each appearance of a character in the dataset\n",
    "def find_frequency(df):\n",
    "    frequency = {}\n",
    "    for index, row in df.iterrows():\n",
    "        for character in row['body']:\n",
    "            if character in frequency:\n",
    "                frequency[character] += 1\n",
    "            else:\n",
    "                frequency[character] = 1\n",
    "    return frequency\n",
    "\n",
    "# Make function to create pandas dataframe of frequency of each character\n",
    "def make_frequency_df(frequency):\n",
    "    freq_df = pd.DataFrame.from_dict(frequency, orient='index', columns=['frequency'])\n",
    "    freq_df = freq_df.sort_values(by=['frequency'], ascending=False)\n",
    "    freq_df['character'] = freq_df.index\n",
    "    freq_df = freq_df.reset_index(drop=True)\n",
    "    freq_df = freq_df[['character', 'frequency']]\n",
    "    return freq_df\n",
    "\n",
    "\n",
    "freq = find_frequency(df)\n",
    "freq_df = make_frequency_df(freq)\n",
    "freq_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is quite a distribution of characters here. We are going to try and keep as many as possible, but also try to align things like apostrophes that have different representations in different encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align encodings\n",
    "df['body'] = df['body'].str.replace('“', '\"')\n",
    "df['body'] = df['body'].str.replace('”', '\"')\n",
    "df['body'] = df['body'].str.replace('’', \"'\")\n",
    "df['body'] = df['body'].str.replace('‘', \"'\")\n",
    "df['body'] = df['body'].str.replace('—', '-')\n",
    "df['body'] = df['body'].str.replace('–', '-')\n",
    "df['body'] = df['body'].str.replace('\\n', ' ')\n",
    "\n",
    "# Remove basic punctuation and digits\n",
    "translator = str.maketrans('', '', '°œ!#$%&\\()*+,./:;=?@[\\\\]^_`{|}~1234567890')\n",
    "df['body'] = df['body'].str.translate(translator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can re-examine the frequency of each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>61428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>34050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>24093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>21378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o</td>\n",
       "      <td>20234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i</td>\n",
       "      <td>19135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n</td>\n",
       "      <td>19085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s</td>\n",
       "      <td>18262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>r</td>\n",
       "      <td>16288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l</td>\n",
       "      <td>12045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character  frequency\n",
       "0                61428\n",
       "1         e      34050\n",
       "2         t      24093\n",
       "3         a      21378\n",
       "4         o      20234\n",
       "5         i      19135\n",
       "6         n      19085\n",
       "7         s      18262\n",
       "8         r      16288\n",
       "9         l      12045"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_aligned = find_frequency(df)\n",
    "freq_df_aligned = make_frequency_df(freq_aligned)\n",
    "freq_df_aligned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preprocessing is helpful prior to tokenization. This includes expanding contracted words and removing stop-words (a, an, the)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand contractions in english\n",
    "df['body'] = df['body'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "\n",
    "# Remove stopwords in english and french\n",
    "stopwords_english = stopwords.words('english')\n",
    "stopwords_french = stopwords.words('french')\n",
    "df['body'] = df['body'].apply(lambda x: [word for word in x if word not in stopwords_english])\n",
    "df['body'] = df['body'].apply(lambda x: [word for word in x if word not in stopwords_french])\n",
    "\n",
    "# Reconcatenate the words into a string\n",
    "df['body'] = df['body'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can tokenize a variety of different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordPiece Tokenizer\n",
    "from transformers import WordpieceTokenizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
