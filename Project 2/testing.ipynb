{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing that is to be done is to import the data and generate splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Datasets/train_cleaned.csv')\n",
    "\n",
    "# Split dataset into training and testing\n",
    "X_df = df['body']\n",
    "y_df = df['subreddit']\n",
    "y_df = y_df.map({'Toronto': 0, 'London': 1, 'Paris': 2, 'Montreal': 3})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, stratify=y_df, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a nice confusion matrix between y_pred and y_test\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create function to plot a confusion matrix\n",
    "def plot_conf_mat(conf_mat):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using Seaborn's heatmap().\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax = sns.heatmap(conf_mat,\n",
    "                     annot=True,  # Annotate the boxes\n",
    "                     cbar=False,\n",
    "                     fmt='g',\n",
    "                     cmap='Blues')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a thorough grid search with CountVectorizer and Naive Bayes\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the pipeline with CountVectorizer and Multinomial Naive Bayes\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "parameters = {\n",
    "    'vectorizer__max_features': [3000, 5000],  \n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],  # Consider different n-gram ranges\n",
    "    'classifier__alpha': [0.01, 0.5, 1.0],  # Smoothing parameter for Naive Bayes\n",
    "    'classifier__fit_prior': [True, False],  # Whether to learn class prior probabilities\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Assign model to a variable\n",
    "best_mnb = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best Accuracy: \", grid_search.best_score_)\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "\n",
    "# Print distribution of y_pred\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print('Class Distribution')\n",
    "print(pd.Series(y_pred).value_counts(normalize=True))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "plot_conf_mat(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a thorough grid search with CountVectorizer and Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the pipeline with CountVectorizer and Logistic Regression\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))  # Increase max_iter if needed\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "parameters = {\n",
    "    'vectorizer__max_features': [3000, 5000],  \n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],  # Consider different n-gram ranges\n",
    "    'classifier__C': [0.1, 1.0, 10.0],  # Inverse of regularization strength\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)  # Assuming X_train and y_train are your training data and labels\n",
    "\n",
    "# Assign model to a variable\n",
    "best_lr = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best Accuracy: \", grid_search.best_score_)\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "\n",
    "# Print distribution of y_pred\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print('Class Distribution')\n",
    "print(pd.Series(y_pred).value_counts(normalize=True))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "plot_conf_mat(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Train a MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the pipeline with CountVectorizer and Multilayer Perceptron\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=3000)),\n",
    "    ('classifier', MLPClassifier())\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "parameters = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],  # Consider different n-gram ranges\n",
    "    'classifier__hidden_layer_sizes': [(100,), (300, 150), (200, 100), (200, 100, 50), (100, 50, 25)],  # Vary hidden layer sizes\n",
    "    'classifier__alpha': [0.001],  # L2 regularization strength\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Assign model to a variable\n",
    "best_mlp = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best Accuracy: \", grid_search.best_score_)\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "\n",
    "# Print distribution of y_pred\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print('Class Distribution')\n",
    "print(pd.Series(y_pred).value_counts(normalize=True))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "plot_conf_mat(conf_mat)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "svm_model = SVC()\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vectorizer__max_features': [3000, 5000],  \n",
    "    'vectorizer__ngram_range': [(1, 2), (1, 3), (1, 4)],  # Consider different n-gram ranges\n",
    "    'classifier__C': [10, 20, 30],  # Regularization parameter\n",
    "    'classifier__degree': [2, 3, 4],  # Degree of the polynomial kernel\n",
    "    'classifier__class_weight': [{0: 1, 1: 1, 2: 1, 3: 1}, {0: 1, 1: 1, 2: 2, 3: 1}, {0: 1, 1: 1, 2: 10, 3: 1}]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Assign model to a variable\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best Accuracy: \", grid_search.best_score_)\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "\n",
    "# Print distribution of y_pred\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print('Class Distribution')\n",
    "print(pd.Series(y_pred).value_counts(normalize=True))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "plot_conf_mat(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', OneVsRestClassifier(BernoulliNB())) \n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'vectorizer__max_features': [1000, 3000, 5000], \n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)], \n",
    "    'classifier__estimator__alpha': [0.001, 0.5, 1.0],  \n",
    "}\n",
    "\n",
    "# Create GridSearchCV instance\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Assign model to a variable\n",
    "best_bnb = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best Accuracy: \", grid_search.best_score_)\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "\n",
    "# Print distribution of y_pred\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print('Class Distribution')\n",
    "print(pd.Series(y_pred).value_counts(normalize=True))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "plot_conf_mat(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', OneVsRestClassifier(RandomForestClassifier())) \n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'vectorizer__max_features': [500, 1000, 3000], \n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)], \n",
    "    'classifier__estimator__n_estimators': [50, 100, 200],  \n",
    "    'classifier__estimator__max_depth': [10, 20, 30, 50],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV instance\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Assign model to a variable\n",
    "best_rfc = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best Accuracy: \", grid_search.best_score_)\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "\n",
    "# Print distribution of y_pred\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print('Class Distribution')\n",
    "print(pd.Series(y_pred).value_counts(normalize=True))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "plot_conf_mat(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most important features\n",
    "feature_importance = best_rfc.named_steps['classifier'].estimators_[0].feature_importances_\n",
    "feature_names = best_rfc.named_steps['vectorizer'].get_feature_names_out()\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
    "feature_importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "feature_importance_df.head(20)\n",
    "\n",
    "feature_importance = best_rfc.named_steps['classifier'].estimators_[1].feature_importances_\n",
    "feature_names = best_rfc.named_steps['vectorizer'].get_feature_names_out()\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
    "feature_importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "feature_importance_df.head(20)\n",
    "\n",
    "feature_importance = best_rfc.named_steps['classifier'].estimators_[2].feature_importances_\n",
    "feature_names = best_rfc.named_steps['vectorizer'].get_feature_names_out()\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
    "feature_importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "feature_importance_df.head(20)\n",
    "\n",
    "feature_importance = best_rfc.named_steps['classifier'].estimators_[3].feature_importances_\n",
    "feature_names = best_rfc.named_steps['vectorizer'].get_feature_names_out()\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
    "feature_importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "feature_importance_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the best performing model to predict the Kaggle test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "London      0.275986\n",
       "Toronto     0.258065\n",
       "Paris       0.250896\n",
       "Montreal    0.215054\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a model\n",
    "best_model = best_svm\n",
    "\n",
    "# Fit the model\n",
    "best_model.fit(X_df, y_df)\n",
    "\n",
    "# Load the Kaggle test set\n",
    "kaggle_test = pd.read_csv('Datasets/test_cleaned.csv')\n",
    "\n",
    "# Make predictions on the Kaggle test set\n",
    "kaggle_test_pred = best_model.predict(kaggle_test['body'])\n",
    "\n",
    "kaggle_test_dict = {\n",
    "    'id': kaggle_test['id'],\n",
    "    'subreddit': kaggle_test_pred\n",
    "}\n",
    "\n",
    "kaggle_test_df = pd.DataFrame(kaggle_test_dict)\n",
    "kaggle_test_df['subreddit'] = kaggle_test_df['subreddit'].map({0: 'Toronto', 1: 'London', 2: 'Paris', 3: 'Montreal'})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "kaggle_test_df.to_csv('Datasets/kaggle_test_predictions.csv', index=False)\n",
    "\n",
    "# See distribution of classes in Kaggle test set\n",
    "kaggle_test_df['subreddit'].value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
